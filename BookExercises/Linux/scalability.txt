Load Balancing
    Purpose:
        Optimize Resource Usage
        Achieve Maximum Throughput
        Minimize Response Time
    Common Load Balancing Techniques:
        Round Robin
        Stick Session (Session Affinity)
        IP Address Affinity


Sticky Sessions/Session Affinity Load Balancing
    How are Sticky Sessions/ Session Affinity Load Balancing Done:
        - Machine is associated with a session as soon as the session is created. 
        - All requests are directed to that machine
        - User data is only at one machine and load is shared
 Issues with Sticky Session
    - Client browser does not support cookies and load balancer will not be able to identify if a request belongs to a session...this causes strange behavior for the users who use no cookie based browsers
    - In case one of the machine fails or goes down, the user info (server by that machine) will be lost and there will be no way to recover the user session


IP Address Affinity
    IP Address is associated with a computer node and all request from a client IP are served by that one node
    - Useful if there is disabled cookies
    Downside:
        - If many users are behind a NATed IP address then all of them will end up using the same server node. This will cause uneven load on the server nodes

Fail Over
    Switching to another machine when one fails
    Done by Load balancer
        - Load Balancer is configured to fail over to another machine when ain machine fails
        - Load Balancer support heart beat check
            - Heart Beat Check
                - Ensures target machine is responding if not then load balancer sends request to another machine or cluster
 


Session replication
    Three Types for Applications:
        - Session persistence + saving the session to a shared file system (Persistence Manager + file store)
        - Session persistence + saving the session to a shared database (Persistence manager + JDBCStore)
        - In- Memory replication = creating an in memory copy of session in all the cluster nodes 



CAP Theorem-
    A distributed system cannot have all of the three following:
        - Consistency - all nodes see the same data at the same time with concurrent updates
        - Availablility - every request recieves a response about success or failure
        - Partition Tolerance - system continues to operate despite arbitrary message loss or failure
    Only two of three conditions can ever be guaranteed to be met by a system

Sharding
    - Architectural approach that distributes a single logical database system into a cluster of machines
    - DOWNSIDES:
        - requires application to be aware of the data location
        - Any addition or deletion of nodes from the system will require some rebalance to be done in the system
        - If you require lot of cross node join queries then your performance will be really bad. So knowing how the data will be used for querying becomes really important
        - Wrong sharding logic may result in worse performance. Make sure you shard based on application need



ACID Property
    - Properties of relational database system
        -Atomicity- This property guarantess that if one part of the transaction fails the enitre transaction will fail not affecting the DB
        - Consistency - This property ensures that any transaction will bring the database from one valid state to another
        - Isolation - property ensures that the concurrent execution of transactions results in a systems state that would be obtained if transaction were executed serially
        - Durable - means that once a transaction has been committed, it will remain so, even in the event of power loss



BASE Property
    - Properties of NoSQL Databases
        - Basically Available - indicates that the system is guaranteed to be available
        - Soft State -indicates that the state of the system may change over tie, even without input. Due to the eventually consistent model
        - Eventual Consistency - System will become consistent over time, given that the system doesn't receive input during that time


Eventual Consistency
    -Property of a system that ensures that any transaction will eventually bring the database from one valid state to another
    - Means there can be intermediate states that are not consistent between nodes
    - USEFUL
        - Scenarios where absolute consistency is not critical
    - DOWNSIDES
        - Cannot be used for use cases where absolute/strict consistencty is required


Shared Nothing Architecture
    - Means no resources are shared between nodes (file storage, memory)
    - Nodes are able to work independently without depending on each other for any work
    - Failure on one node only affects users of the node..others continue to work
    - Highly scalable to avoid existence of a single bottleneck
    - Linear Scalablilty
    _ Can scale infinitely simply by adding nodes in the form of inexpensive machines


Updating Heavy Traffic Site
    Before Deploying
        - test new changes and ensure it works in test enviroment that is identical to production system
        - Do automation test cases as much as possible
        - Create automated sanity test script/smoke test that can be run on production
        - Create scripts for all manual tasks avoiding any hand typing mistakes during deployment
        - Test the script to make sure they work on a non-production enivorment
        - Keep the build artifacts ready 
        - Create a checklist of things to do on day of deployment
        - Rehearse. Deploy on non-prod that is identical to prod
    On Deploying
        - Keep backup of current site/data to be able to rollback
        - use sanity test cases before doing a lot of in depth testing


Distributed Lock Manager (DLM) - Google's Chubby
    -Chubby provides an interface like a distrubuted file system with advisory locks with a design emphasis on availability and reliability as opposed to high performance
    - For use within a loosely coupled distributed system of large numbers of small machines connected by a high speed network
    - Reliability and availabiity most important
        - Throughput and storage capacity secondary
    - Client interface is similar to that of a simple file system with whole-file reads and writes augmented with advisory locks and notification of various events like modification
    - Chubby was built to help deal with the problem of electing a leader from among a set of otherwise equivalent servers


    -Advantages over a client library (like Paxos)
        - Developers do not plan for high availability in the way they would wish, a lock server makes it easier to maintain existing program structure and communication patterns
            - One acquires lock to become master
            - pass an additional integer with the write RPC and an if-statement to the file server to reject the write if acquisition count is lower than the current value
        - Services that elect a primary need a means for advertising the results
            - Chubby uses consistent client caching rather than time based caching
        - A lock based interface is more familiar at least programmers think it is...it gives the illusion on synchronization
        - Finally distributed consensus algorithms use quorums to make decisions so they use several replicas. Chubby uses 5....on a client system a single client can obtain a lock so the lock service reduces the number of servers needed for reliable client service ... called consesnus service

- CHUBBY CELL STRUCTURE
        - Small set of servers known as replicas
        - They use distributed consensus protocol to elect a master for a period called a master lease
        - replicas maintain copies of a simple db but the master initiates reads and writes of the database. replicas simply copy updates from the master sent using the concensus protocol
        - write requests are propagated to all replicas and are acknowledged once it has reached most replicas
        - Reads are satisfied by the master alone
    - If there is a failure
        - system selects a fresh machine from a free pool and starts the lock server bianry on it updates the DNS tables and replaces the IP of the failed machine with the new one.
        - The master polls DNS and notices the change
        - The master then updates the list of the cells members in the cell's database
        - New replica obtains a copy of the database from a combination of backups then updates them based on that of the active replicas
        - Once it has processed a request by the master the new replica is eligible to vote
    - Chubby Clients Cache
        - When file data is to be changed the master send invalidations for every client that may have cached it and the client flushes it
        - Once the server has word that every client has invalidated its cache.
        - It invalidates rather than updated because the client would need to get constant updates 



Memcached
    - general purpose dsitributed memory caching system.
    - Provides large hash table distributed across multiple machines. 
    - When table is full subsequent inserts cause older data to be purged in least recently used order. 
    - Layer requests and additions into RAM before falling back on a slower backing store
    - Architecture
        - Client -server
        - Servers maintan key- value associative array
        - Clients populate it and query by key
        - Clients access servers at port 11211
        - Each client knows all servers 
        - Servers don't know each other
        - PROCESS
            - If clients want to set or read a value it first computes the value of the hash to determine which server to use. (Gives Sharding and shared nothing architecture) 
            - Server computes the hash of the key to determine where to store or read the corresponding value.
            - Servers keep values in RAM until it runs out then it discards the oldest value



Multi-threading
    - Ability of a CPU or a single core to execute multiple processes or threads concurrently
    - Different than multiprocessing because multi-threading the processes and threads share teh resources of single or multiple cores: The CPUs and the translation lookaside buffer
    - Aim is to increase utilization by using thread level as well as instruction level parallelism.
    
    - ADVANATAGES:
        - If a thread gets a lot of cache misses other threads can continue taking advantage of unused computing resources
        - If a thread cannot use all the computing resources of the CPU, running another thread may prevent those resources from being idle
        - If several threads work on the same set of data they can share their cache, leading to better cache usage or synchronization on its values
    
    - DISADVANTAGES
        - Multiple threads can interfere with each other when using hardware resources so due to the excess resources needed to acommadate thread switching hardware single threads can be degraded
        - Efficieincy varies ex: Intel Hyper-Threading claims 30% improvement and a program performing a loop of floating point operations ay have 100% whereas assembly language programs do not benefit and may see degraded performance
        - Thread Scheduling 
        - hardware support is morevisisble to software than multiprocessing meaning more changes needed to software

    - TYPES
        - Interleaved/ Temporal
            - Coarse Grained Multithreading
                - One thread runs until it is blocked by an event that would cause a stall then while waiting the processor would switch execution to another thred until the original was ready to run
            - Interleaved Multithreading (Barrel Processor)
                - aka fine-grained, time sliced, preemptive
                - time slice given to each active thread is one CPU cycle
            - Simulataneous Multithreading
                - Most advanced kind
                - Exploits parallelism available across multiple threads to decreas the waste associated with ununsed slots
                - Temporal Multihtreading
                - A superscalar processor can issue instructions from multiple threads every CPU cycle
                - Additional Cost - each pipeline stage tacks the thread ID of each instruction being processed.
